---
title: "The Bird of Catastrophy"  
author: "CERM"  
date: "`r format(Sys.time(), '%d %B, %Y')`" 

output:
  html_document:
    theme: journal
    toc: true 
    toc_float: true  
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

## Black Swans
The term "Black Swan" originates from the belief that all swans were white because those were the only ones observed by westerners.  This belief continued until 1697 when black swans were found in Australia, rewriting accepted science in one swipe.  The term becomes a metaphor for unprecedented and unexpected events and eventually the title of a best selling book by Nasim Taleb.  
  
There are several characteristics that all Black Swans have in common. The first is that it comes as a surprise to the observer.  It is an outlier outside the realm of regular expectations because nothing in the past points to its existence.  Typically this is because the time frame of which data is available is too short to contain one of these Black Swans due to their rarity.  
  
The second factor that all Black Swans have in common is that they are rationalized after the fact, making them "predictable" in retrospect in the observers mind.  Explanations are created to convince the observer that if they had only looked, the evidence was there the whole time.  Even though there is nothing in the past that points to it.
  
The third characteristic is that it has extreme impact beyond anything ever observed previously.  The consequences can be thousands of times a "typical" incident.  The three ingredients to a Black Swan are the unpredictability, consequences not seen in any historical record and rationalization after the fact. 

## How bad can bad be
In any risk analysis the question always at hand is, how bad can it be?  The response is reflexively, how bad has it been in the past. The problem with that approach is that Black Swans are a rare bird and your window of observations might be too short to have one in your data set. In addition, when people are asked about the magnitude of risk for something in which hard data is sparse or non-existent they will base their estimates based on personal experience which is most likely skewed toward the lower quartiles. People are more likely to five credibility to stories than they are abstract statistics since it is easier to mentally process.
  
## Black Swans and Statistics  
Most of the traditional statistics serve us well if we never venture far from the average. It can be seen in the following examples that catastrophic risk does not adhere to such norms. Some distributions are so common in many everyday applications where the effects are additive and the deviations from the mean are small.  The classic example of this is height of people.  The average height of men is about 5' 10" with a standard deviation of 4".  It would be very rare to come across someone that is more than 2 or 3 standard deviations from that mean.  We don't have giants or Lilliputians walking around!  But in the field of risk, a Black Swan can be a hundred or a thousand times the mean. This is because the variables that drive risk are multiplicative rather than additive.  This means that the results have the ability to increase exponentially.  That is why it is very dangerous to make assumptions that make something computationally convenient (e.g. normally distributed or taking an average) because Black Swans live in the wild, out on the tails of the distribution where traditional statistics would predict the likelihood of something of that magnitude is essentially zero.  The first characteristic of Black Swans is that they are a rare bird, your period of time that you have data for might be too short to have ever seen one.  If your entire data set contains nothing but ordinary "White Swans" it does not prove the lack of existence of Black Swans but a single Black Swan is sufficient to disprove that theory of its non-existence and one Black Swan can put a company out of business in one swipe.
  
It can be said that statistics and probability is a statement about the future based on observations in the past. But risk is not a constant thing.  People constantly alter their behavior based on observed or perceived dangers therefor altering future outcomes.  Donald Rumsfeld, former  Secretary of Defense talked about the three types of "knowns".  The first is the "known knowns", things that you know for certain.  The second is the "known unknowns", these are the things that you know you don't know but since you are aware of them you could be acquired through time, effort or other resources.  The third and most consequential is the "unknown unknowns", these are the things that you don't know you don't know - you are completely unaware of them in any way. This is the origins of Black Swans.  For if the factors that could lead to a Black Swan were known, the end user would have made adjustments to their behavior to account for them.  But instead the average person careens ahead attempting to mitigate and prevent the directly perceived more common risk factors that are seen on a regular basis, in the meantime just out of sight could be an event that end their very existence. This is known as availability bias, the more recent are given more credibility even if evidence to the contrary exists.  An example would be people that they say they would never swim in the ocean after hearing of a shark attack, even though it is an extremely rare event when compared to things like being attacked by dogs.  
  
## You Make the Call
There used to be a commercial that played during NFL games where they would show footage of an unusual play from an NFL game and then ask the audience, "You make the call". In this exercise you are the risk engineer and your boss hands you the following data.  

```{r insurance losses, fig.cap="Figure 2: Insurance Losses"}

setwd("C:/Users/Joel/OneDrive/Analysis/EVT")
library(dplyr)
library(ggplot2)
#library(readr)
library(MASS)
library(ggpubr)
library(data.table)
library(car)
library(bookdown)
eq_insurance <- fread("earthquake_loss.csv")
ggplot(eq_insurance[-24], aes(year, loss_ratio))+geom_bar(stat = "identity", fill='steelblue2',col='black')+theme_bw(14, "serif")+scale_y_continuous(breaks=seq(0,140,by=20))+labs(title = "Earthquake Insurance Loss Ratios by Year",subtitle = "1971 - 1993", x="Year", y="Loss Ratio")
#ggplot(insurance[-24], aes(loss_ratio))+geom_histogram( fill='steelblue2',col='black')+theme_bw()+scale_y_continuous(breaks = seq(0,10, by=2))
```
  
The conclusion of this is that in 1994 the Northridge Earthquake hit with a loss ratio of 2273, almost 700 times the median loss ratio of the previous twenty-three years.  Even if someone was to assume worst case was the mean plus three standard deviations, which under a normal distribution covers 99.7% of the data they would have still been off by a factor of more than 20.  It can be seen from this example that catastrophic risk does not follow Gaussian statistical norms.  The Gaussian distribution is very common in any application where the effects are additive.  So common that it often referred to as the Normal distribution.  This works very well in applications where the deviations from the mean are small.  The classic example of this is people's height.  The average height of men is about 5' 10" with a standard deviation of 4".  It would be very rare to come across someone that is more than 2 or 3 standard deviations from that mean.  We don't have giants or Lilliputians walking around!  But in the field of risk, a Black Swan can be a hundred or a thousand times the mean. This is because the variables that drive risk are multiplicative rather than additive.  These means that the results have the ability to increase exponentially.  
  
This also means that even analysis methods like Monte Carlo even though they account for stochastic nature of different variables, are better at predicting average behavior of something than the extremes. This is because the sampling distributions used are more prone to model the "typical" rather than the extreme consequently leading to "typical" results.

## The Perils of the Normal Distribution  
The following simulation makes 1,000 random draws from a standard normal distribution (zero mean and unit standard deviation) and repeats this process 1,000 times. With each iteration it calculates the mean and selects the maximum value.  It then plots them as blue and red markers respectively. The bottom plot shows that the extreme values converge to a Gumbel distribution known as a Type I extreme value distribution. But it can be seen that even the samples are drawn at random the averages never get far from the average of the population and the extremes *start* at about 3 standard deviations from the mean. 

```{r gumble, fig.height=6}
library(locfit)
library(logspline)

# Normal Origins #
par(mfrow=c(3,1))
x = rnorm(1000,0,1)
plot(
  logspline(x),
  xlim = c(-5, 5),
  ylim = c(0, 0.5),
  font = 2,
  cex.lab = 2,
  font.lab = 2,
  xlab = "Normal Distribution"
)
hist(
  x,
  prob = T,
  ylab = "",
  main = "",
  font = 2,
  cex.lab = 2,
  font.lab = 2,
  col = 'white',
  add=T
)

N = 1000
ave = matrix(NA,nrow=N,ncol=1)
max1 = matrix(NA,nrow=N,ncol=1)

for (i in 1:N)
{
  x = rnorm(N,0,1)

  lines(locfit(~x),col="grey")
  points(mean(x),0,col="blue",pch=17)
  points(max(x),0,col="red",pch=17)
  ave[i] = mean(x)
  max1[i] = max(x)
  # Sys.sleep(0.01)
}

# # Sys.sleep(1)
plot(
  locfit( ~ ave),
  xlim = c(-5, 5),
  ylim = c(0, 9),
  ylab = "",
  cex.lab = 2,
  font = 2,
  font.lab = 2,
  xlab = "Normal Distribution of Averages",
  col = "white"
)
lines(locfit( ~ ave), lwd = 2, col = "blue")

# Sys.sleep(1)

plot(
  locfit( ~ max1),
  xlim = c(-5, 5),
  font = 2,
  font.lab = 2,
  ylab = "",
  xlab = "Extreme Value Distribution (Gumbel)",
  cex.lab = 2,
  col = "white"
)
lines(locfit(~max1),lwd=2,col="red")
```

IN 
`r length(max1[max1>3])`

## Catastrophic Risk  
It is well known that casinos spend significant sums of money on surveillance and technology to prevent losses due to cheating at the gambling tables.  Yet the biggest loss to a casino came not from cheating, but from the loss of headline entertainment act when Roy Horn one half of the Siegfried and Roy was attacked on stage by one of the tigers in their act.  The total economic loss is estimated at \$100 million dollars when the show closed permanently with no immediate replacement.  The casinos were building defenses against the most common threat (gambling cheats) but were completely blind to the possibility that the loss of this one act impact the casino for years to come and in ways they hadn't even thought of.  Like most Black Swans, it comes from an area that is totally non-existent in the historical data.

While history is not always a good predictor of the future, typically that is all is available to mine for data.  In the case of pipeline risk, PHMSA publishes all pipeline incident data.  An incident is an accidental release from a pipeline that includes any of the following: Greater than \$50,000 in property damage, an injury or fatality.  Then if you were to take that data and scale the injuries and fatalities to dollar values using an appropriate multiplier to arrive at a total consequence of failure (CoF), the data would have a histogram as shown in Figure 1.  Note: the range of data for the histogram extends out to $10^9$ but for the purposes of scale it is truncated at $10^8$.
  
```{r import data, fig.cap="Figure 1: CoF Data Density Curve"}
library(dplyr)
library(ggplot2)
#library(readr)
library(MASS)
library(ggpubr)
library(data.table)
library(car)
library(bookdown)
#setwd("D:/Documents/Analysis/catastrophic")
#setwd("~/PPIM2019")
incidents <- fread("all_combine.csv")
incidents <- incidents[is.na(Year)==FALSE]
#incidents <- incidents[1:2716,] #Drop 40 NAs at the end

incidents[,inflation_adjstd :=incidents$TOTAL_COST_IN84*2.49] #Per CPI calculator adjusted 1984 to 2019
incidents[, CoF:=inflation_adjstd+INJURE*0.33*10e6+FATAL*10e6]
incidents <- incidents[is.na(CoF)==FALSE]

incidents %>%
  ggplot(aes(CoF)) +
  geom_histogram(fill = '#FF3030',
                 col = 'black',
                 alpha = 0.8) +
  geom_rug(col = 'blue') +
  theme_bw() +
  xlim(0, 1e8) +
  ylim(0, 60) +
  labs(title = "Consequence of Failure",
       subtitle = "PHMSA Gas Transmission Incidents 1986 - 2019",
       x = "CoF (log Scale)")

```

In the field of risk and in most naturally occurring phenomena, the majority of the data will almost always lie in a predictable range near the lower end of the scale but the incidents that should keep one up at night are the ones to the far right which are much rarer but the consequences can be hundreds or thousands of times larger than the average.  In the CoF data in Figure 1 the median incident is around \$170,000 and the maximum is over \$1 billion a difference of over 6,000 times.  This is common in any application of risk, not just pipeline risk. There will be a plethora of data at the lower end of the scale with outliers extending out several magnitudes of order.  
  
```{r}
incidents %>%
  filter(CoF >= 5e7) %>%
  ggplot(aes(CoF)) +
  geom_histogram(fill = '#FF3030',
                 col = 'black',
                 alpha = 0.8) +
  geom_rug(col = 'blue') +
  theme_bw() +
  labs(title = "Consequence of Failure",
       subtitle = "PHMSA Gas Transmission Incidents 1986 - 2019",
       x = "CoF (log Scale)")
```
  
If a normal distribution was fit to the incident CoF data it would have the appearance of being a good fit through the middle of the curve with some outliers at the higher end.  But if you were to magnify this tails area you would see that there are far more of these extreme events than would be expected based on a normal distribution. This why the normal distribution is only suitable model for such events that phenomena based on sums and averages but a really poor model for Black Swans where the effects are multiplied by magnitudes of order between the mean and the extremes. Traditional statistics would predict the likelihood of something of the magnitude of these consequences would be effectively zero, yet there are several examples in the 33 years of data. In fact the data count departs from the predicted count by a factor of 10 at the higher CoF values. The seemingly goodness of fit in the more prevalent lower end will often lead to the disregarding of the extreme events as so remote as not to be given serious consideration, much to their peril.  

## Extremes  
The aim of statistical theory of extreme values is to explain the observed extremes arising in the samples of given sizes, or for a given period and to forecast extremes that may be expected to occur within a certain sample size, time, area, etc. There are two types of predictions that are can be made, one is the intensity of an event and the other is the frequency.  The frequency can be based on a set of observations or on a known period of return.  The founders of the calculus of probabilities were too occupied with the general behavior of statistical masses to be interested in the extremes. Nineteenth century mathematician Fourier stated that, for the normal distribution, the probability of an absolute deviation to exceed $3\sqrt 2$ times the standard deviation is about 1 in 50,000, and could therefore be neglected. From this small probability, the erroneous conclusion was drawn that about three times the standard deviation should be considered as the maximum for any statistical variable. The idea that three times the standard deviation should be considered as maximum-irrespective of the number of observations and of the distribution still prevails among most "practical" people. However, the fallacy of this rule is obvious. If the variable being studied is unlimited then the largest value is unlimited as well.  Emil Gumbel who did a lot of the pioneering work on extreme value theory is quoted, "There will always be one (or more) value that will exceed all others." and the President's Water Commission stated that,"However big floods get, there will always be a bigger one coming; so says one theory of extremes, and experience suggests it is true."

Fortunately this phenomena is nothing new and has been studied at length in areas such as floods and insurance risks. The first problem of the extremes to be discussed is when the available data is set of observations over a fixed period of time and the 
  
## Prediction of Extreme Events
Black Swans occur without warning and have their origins in "unknown unknowns" therefore their time and place of happening are not predictable. Thought the time and place are not predictable there are methods that allow us to peek into the likelihood of an event of a certain size. This a well known realm of study in the area of floods and extremes of weather. If a dam was being designed the engineer needs to have some sort of idea how large a flood it would have to contain, even though the historical data might not contain something of that magnitude. 
  
To be able to accommodate the design of things such as dams against historical floods or skyscrapers against wind loads the theory of extreme distributions was developed.  This separate branch of statistics deals the probability of rare and extreme events. As the name implies it is only concerned about the far right or left-tailed events. There are two ways of examining these types fo events with the GEVD, one is the peak over threshold and the block maxima. In the peak over threshold method the designer is only concerned with the data points over a certain threshold. In the block maxima approach only the maximum value for each time period is considered, for example the maximum rainfall recorded each year for 20 years. How does this compare to PHMSA incident data?  
  
```{r PHMSA GEVD}
library(evd)
# inc_10m <- filter(incidents, CoF>1e7)
# fit_PHMSA <- fevd(inc_10m$CoF)
# q_phmsa <- qevd(c(0.975), fit_PHMSA$results$par[1],fit_PHMSA$results$par[2],fit_PHMSA$results$par[3])/1e6
# p_SB <- pevd(max(incidents$CoF), fit_PHMSA$results$par[1],fit_PHMSA$results$par[2],fit_PHMSA$results$par[3])
```
  
If a extreme value distribution is fit to the PHMSA, incident data using a threshold of \$10 million, the far right tail of the 95% prediction interval (97.5 percentile) would be at about \$900 million which is within 11% of the CoF of San Bruno. Using the same model, it would place San Bruno at almost the 98 percentile, implying that there is a slightly greater than 2% chance of San Bruno being exceeded in the future. This is congruent with the quote from Emil Gumbel who did a lot of the pioneering work on extreme value theory, "There will always be one (or more) value that will exceed all others." and the President's Water Commission in 1932 stated that,"However big floods get, there will always be a bigger one coming; so says one theory of extremes, and experience suggests it is true."
  
## Conclusion  
Even though there is theoretical backing to predicting the likely magnitude of extremes it still does not predict where or when they will occur. Because of this, it is important to have what can be termed as defense in depth. Meaning that there are enough redundant layers of protection between the ever-present hazard and an actual accident that any gap in a single layer does not give a pathway between the hazard and a potentially catastrophic accident.  These defensive barriers take the form of procedures, materials, maintenance and pipeline patrols to name a few.  The more redundant and diverse the barriers the less likely a Black Swan has any viability in your system. Above all else follow the Noah Rule: Predicting rain does not count, building arks does. As risk engineers we are called to not just be rain predictors but ark builders as well.
